import os
from flask import Flask, render_template, request, jsonify, Response, stream_with_context
from openai import OpenAI
from dotenv import load_dotenv
import json
from datetime import datetime

load_dotenv()

app = Flask(__name__)

class AIService:
    def __init__(self):
        self.default_api_key = os.getenv("AI_API_KEY")
        self.base_url = os.getenv("AI_BASE_URL")
        
        if not self.default_api_key or self.default_api_key == "your_api_key_here":
            raise ValueError("AI_API_KEY must be set in .env file")
        if not self.base_url:
            raise ValueError("AI_BASE_URL must be set in .env file")
            
        # ëª¨ë¸ë³„ í‚¤ ë§¤í•‘ ë¯¸ë¦¬ ì •ì˜ (í•„ìš” ì‹œ)
        # ì˜ˆ: AI_API_KEY_QWEN3_235B ë“±ìœ¼ë¡œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ë‘ë©´ ê°œë³„ ì ìš©ë¨
    
    def _get_client_for_model(self, model_name):
        """ëª¨ë¸ì— ìµœì ì¸ API í‚¤ë¡œ í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        # ëª¨ë¸ëª…ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ê³  ëŒ€ë¬¸ìë¡œ ë³€í™˜ (ì˜ˆ: qwen3-235b -> QWEN3_235B)
        env_suffix = model_name.replace("-", "_").replace(".", "_").upper()
        specific_key = os.getenv(f"AI_API_KEY_{env_suffix}")
        
        # íŠ¹ì • ê·¸ë£¹ í‚¤ (ì˜ˆ: GPT ê³„ì—´)
        if "gpt" in model_name.lower() or "opus" in model_name.lower():
            gpt_key = os.getenv("AI_API_KEY_GPT_OPUS")
            if gpt_key: specific_key = gpt_key
            
        key = specific_key or self.default_api_key
        return OpenAI(api_key=key, base_url=self.base_url)
    
    def get_available_models(self):
        """ì„¤ì •ëœ ëª¨ë“  API í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì ‘ê·¼ ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
        all_models = set()
        keys_to_try = {self.default_api_key}
        
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ëª¨ë“  AI_API_KEY_ ë¡œ ì‹œì‘í•˜ëŠ” í‚¤ ìˆ˜ì§‘
        for key, value in os.environ.items():
            if key.startswith("AI_API_KEY_") and value:
                keys_to_try.add(value)
        
        for key in keys_to_try:
            if not key or key == "your_api_key_here": continue
            try:
                client = OpenAI(api_key=key, base_url=self.base_url)
                models = client.models.list()
                for model in models.data:
                    all_models.add(model.id)
            except Exception as e:
                print(f"Error fetching models for key {key[:10]}...: {e}")
        
        # ë§Œì•½ API í˜¸ì¶œë¡œ ê°€ì ¸ì˜¨ ëª¨ë¸ì´ ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ì„¸íŠ¸ ë°˜í™˜
        if not all_models:
            default_models = os.getenv("DEFAULT_MODELS", "")
            return [m.strip() for m in default_models.split(",") if m.strip()]
            
        return sorted(list(all_models))
    
    def chat_stream(self, messages, model="qwen3-235b"):
        """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ"""
        try:
            client = self._get_client_for_model(model)
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                stream=True
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            yield f"\n\nâŒ Error ({model}): {str(e)}"

ai_service = AIService()

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index.html')

@app.route('/api/models', methods=['GET'])
def get_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    models = ai_service.get_available_models()
    return jsonify({"models": models})

@app.route('/api/chat', methods=['POST'])
def chat():
    """ì±„íŒ… API - ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ"""
    data = request.json
    messages = data.get('messages', [])
    model = data.get('model', 'qwen3-235b')
    
    def generate():
        for content in ai_service.chat_stream(messages, model):
            yield f"data: {json.dumps({'content': content})}\n\n"
        yield "data: [DONE]\n\n"
    
    return Response(
        stream_with_context(generate()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )

@app.route('/api/health', methods=['GET'])
def health():
    """í—¬ìŠ¤ ì²´í¬"""
    return jsonify({"status": "ok", "timestamp": datetime.now().isoformat()})

if __name__ == '__main__':
    print("ğŸš€ Starting Tokamak AI Chat Interface...")
    print("ğŸ“¡ Server running at: http://localhost:5000")
    print("ğŸ”‘ Using API Key:", os.getenv("AI_API_KEY")[:10] + "..." if os.getenv("AI_API_KEY") else "NOT SET")
    app.run(debug=True, port=5000, threaded=True)
